#!/usr/bin/env python3
"""Demo script showing GenerationEngine usage."""

import asyncio
import logging
from pathlib import Path
from unittest.mock import Mock, AsyncMock

from saigen.core.generation_engine import GenerationEngine
from saigen.models.generation import GenerationRequest, LLMProvider
from saigen.llm.providers.base import LLMResponse


# Set up logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


async def demo_generation_engine():
    """Demonstrate GenerationEngine functionality."""
    print("🚀 GenerationEngine Demo")
    print("=" * 50)
    
    # Configuration for the engine
    config = {
        "llm_providers": {
            "openai": {
                "api_key": "demo-api-key",  # In real usage, use environment variable
                "model": "gpt-4o-mini"
            }
        }
    }
    
    # Sample saidata YAML that would be generated by LLM
    sample_saidata_yaml = """
version: "0.2"
metadata:
  name: "nginx"
  display_name: "Nginx"
  description: "High-performance web server and reverse proxy"
  category: "web-server"
  license: "BSD-2-Clause"
  urls:
    website: "https://nginx.org"
    documentation: "https://nginx.org/en/docs/"

providers:
  apt:
    packages:
      - name: "nginx"
        version: "latest"
    services:
      - name: "nginx"
        enabled: true
        
  brew:
    packages:
      - name: "nginx"
        
  winget:
    packages:
      - name: "nginx.nginx"
"""
    
    # Mock the OpenAI provider for demo purposes
    # In real usage, this would make actual API calls
    from unittest.mock import patch
    
    with patch('saigen.core.generation_engine.OpenAIProvider') as mock_provider_class:
        # Create mock provider
        mock_provider = Mock()
        mock_provider.is_available.return_value = True
        mock_provider.get_provider_name.return_value = "openai"
        mock_provider.generate_saidata = AsyncMock(return_value=LLMResponse(
            content=sample_saidata_yaml,
            tokens_used=1200,
            cost_estimate=0.0024,
            model_used="gpt-4o-mini",
            finish_reason="stop"
        ))
        mock_provider_class.return_value = mock_provider
        
        # Initialize the generation engine
        engine = GenerationEngine(config)
        
        print(f"✅ Initialized GenerationEngine")
        print(f"📊 Available providers: {engine.get_available_providers()}")
        
        # Create a generation request
        request = GenerationRequest(
            software_name="nginx",
            target_providers=["apt", "brew", "winget"],
            llm_provider=LLMProvider.OPENAI,
            use_rag=True
        )
        
        print(f"\n🎯 Generating saidata for: {request.software_name}")
        print(f"🔧 Target providers: {request.target_providers}")
        
        # Generate saidata
        result = await engine.generate_saidata(request)
        
        # Display results
        print(f"\n📋 Generation Results:")
        print(f"   ✅ Success: {result.success}")
        print(f"   ⏱️  Time: {result.generation_time:.2f}s")
        print(f"   🤖 LLM Provider: {result.llm_provider_used}")
        print(f"   🎫 Tokens Used: {result.tokens_used}")
        print(f"   💰 Cost Estimate: ${result.cost_estimate:.4f}")
        
        if result.success and result.saidata:
            print(f"\n📦 Generated SaiData:")
            print(f"   📛 Name: {result.saidata.metadata.name}")
            print(f"   📝 Description: {result.saidata.metadata.description}")
            print(f"   🏷️  Category: {result.saidata.metadata.category}")
            print(f"   🔗 Website: {result.saidata.metadata.urls.website if result.saidata.metadata.urls else 'N/A'}")
            print(f"   🛠️  Providers: {list(result.saidata.providers.keys()) if result.saidata.providers else []}")
            
            # Save to file
            output_path = Path("demo_nginx.yaml")
            await engine.save_saidata(result.saidata, output_path)
            print(f"   💾 Saved to: {output_path}")
            
        # Show validation errors if any
        if result.validation_errors:
            print(f"\n⚠️  Validation Errors:")
            for error in result.validation_errors:
                print(f"   - {error.field}: {error.message}")
        
        # Show generation statistics
        stats = engine.get_generation_stats()
        print(f"\n📊 Engine Statistics:")
        print(f"   🔢 Total Generations: {stats['total_generations']}")
        print(f"   🎫 Total Tokens: {stats['total_tokens_used']}")
        print(f"   💰 Total Cost: ${stats['total_cost_estimate']:.4f}")
        
        # Demonstrate validation of existing file
        if Path("demo_nginx.yaml").exists():
            print(f"\n🔍 Validating saved file...")
            validation_result = await engine.validate_saidata_file(Path("demo_nginx.yaml"))
            print(f"   ✅ Valid: {validation_result.is_valid}")
            print(f"   ⚠️  Warnings: {len(validation_result.warnings)}")
            print(f"   ❌ Errors: {len(validation_result.errors)}")
            
            if validation_result.warnings or validation_result.errors:
                report = engine.format_validation_report(validation_result)
                print(f"\n📋 Validation Report:")
                print(report)


async def demo_error_handling():
    """Demonstrate error handling in GenerationEngine."""
    print("\n🚨 Error Handling Demo")
    print("=" * 30)
    
    # Create engine without providers
    engine = GenerationEngine({})
    
    # Try to generate with unavailable provider
    request = GenerationRequest(
        software_name="test-software",
        llm_provider=LLMProvider.OPENAI
    )
    
    result = await engine.generate_saidata(request)
    
    print(f"❌ Expected failure - Success: {result.success}")
    if result.validation_errors:
        print(f"🔍 Error: {result.validation_errors[0].message}")


async def main():
    """Run the demo."""
    try:
        await demo_generation_engine()
        await demo_error_handling()
        
        print(f"\n🎉 Demo completed successfully!")
        print(f"💡 Check the generated 'demo_nginx.yaml' file")
        
    except Exception as e:
        logger.error(f"Demo failed: {e}")
        raise


if __name__ == "__main__":
    asyncio.run(main())